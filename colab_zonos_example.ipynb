{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎵 Zonos TTS - 구글 코랩\n",
        "\n",
        "Zonos Text-to-Speech 모델을 구글 코랩에서 사용하는 예제입니다.\n",
        "\n",
        "## 공식 문서 기준 정확한 구현\n",
        "- **make_cond_dict** 파라미터: 공식 문서와 100% 일치\n",
        "- **감정 벡터**: [0.3077, 0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.2564, 0.3077]\n",
        "- **speaking_rate**: 0-40 (30=very fast, 10=slow)\n",
        "- **pitch_std**: 0-400 (20-45=normal, 60-150=expressive)\n",
        "- **fmax**: 22050 (44.1kHz) 또는 24000 (48kHz)\n",
        "- **unconditional_keys**: 기본값 {\"vqscore_8\", \"dnsmos_ovrl\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 시스템 의존성 설치 (eSpeak-ng)\n",
        "!apt-get update\n",
        "!apt-get install -y espeak-ng\n",
        "\n",
        "# 2. 필요한 라이브러리 설치\n",
        "!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers gradio\n",
        "\n",
        "# 3. Zonos 저장소 클론\n",
        "!git clone https://github.com/Zyphra/Zonos.git\n",
        "%cd Zonos\n",
        "\n",
        "# 4. Zonos 설치\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from zonos.model import Zonos\n",
        "from zonos.conditioning import make_cond_dict\n",
        "from zonos.utils import DEFAULT_DEVICE as device\n",
        "\n",
        "# 모델 로드 (Transformer 버전 사용)\n",
        "print(\"모델 로딩 중...\")\n",
        "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
        "print(\"모델 로딩 완료!\")\n",
        "\n",
        "# 기본 샘플 실행 (공식 문서 기본값 사용)\n",
        "text = \"Hello, this is a test of Zonos text-to-speech in Google Colab!\"\n",
        "cond_dict = make_cond_dict(\n",
        "    text=text, \n",
        "    speaker=None, \n",
        "    language=\"en-us\",\n",
        "    # 공식 문서 기본값 사용\n",
        "    emotion=[0.3077, 0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.2564, 0.3077],\n",
        "    speaking_rate=15.0,\n",
        "    pitch_std=20.0,\n",
        "    fmax=22050.0\n",
        ")\n",
        "conditioning = model.prepare_conditioning(cond_dict)\n",
        "print(\"음성 생성 중...\")\n",
        "codes = model.generate(conditioning)\n",
        "wavs = model.autoencoder.decode(codes).cpu()\n",
        "output_file = \"sample.wav\"\n",
        "torchaudio.save(output_file, wavs[0], model.autoencoder.sampling_rate)\n",
        "print(f\"✅ 음성 파일이 {output_file}에 저장되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 구글 코랩용 Gradio 인터페이스 (공식 문서 기준 정확한 구현)\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from zonos.model import Zonos\n",
        "from zonos.conditioning import make_cond_dict\n",
        "from zonos.utils import DEFAULT_DEVICE as device\n",
        "import gc\n",
        "\n",
        "# 전역 모델 변수 확인 및 로드\n",
        "print(\"🔍 모델 상태 확인 중...\")\n",
        "if 'model' not in globals():\n",
        "    print(\"⚠️ 모델이 로드되지 않았습니다. Gradio에서 모델을 로드합니다...\")\n",
        "    try:\n",
        "        model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
        "        print(\"✅ Gradio에서 모델 로드 완료!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 모델 로드 실패: {e}\")\n",
        "        model = None\n",
        "else:\n",
        "    print(\"✅ 모델이 이미 로드되어 있습니다.\")\n",
        "\n",
        "# TTS 함수 정의 (공식 문서 기준 정확한 파라미터)\n",
        "def generate_speech(text, language=\"en-us\", happiness=0.3077, sadness=0.0256, disgust=0.0256, fear=0.0256, surprise=0.0256, anger=0.0256, other=0.2564, neutral=0.3077, emotion_unconditional=False, speaking_rate=15.0, pitch_std=20.0, fmax=22050.0, speaker_unconditional=False, fmax_unconditional=False, pitch_unconditional=False, rate_unconditional=False, seed=None, audio_file=None):\n",
        "    try:\n",
        "        print(f\"🔍 디버깅: 텍스트='{text}', 언어='{language}', 시드='{seed}', 오디오파일='{audio_file}'\")\n",
        "\n",
        "        # 모델 확인\n",
        "        if model is None:\n",
        "            return \"❌ 모델이 로드되지 않았습니다. 페이지를 새로고침하고 다시 시도해주세요.\", \"오류 발생\"\n",
        "\n",
        "        print(\"✅ 모델 확인 완료\")\n",
        "\n",
        "        # 시드 설정\n",
        "        if seed is not None:\n",
        "            torch.manual_seed(seed)\n",
        "            used_seed = seed\n",
        "            print(f\"🎲 시드 설정: {seed}\")\n",
        "        else:\n",
        "            # 랜덤 시드 생성\n",
        "            used_seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
        "            torch.manual_seed(used_seed)\n",
        "            print(f\"🎲 랜덤 시드 생성: {used_seed}\")\n",
        "\n",
        "        # 음성 클로닝 처리\n",
        "        speaker_embedding = None\n",
        "        if audio_file is not None:\n",
        "            try:\n",
        "                print(\"🎤 음성 클로닝 처리 중...\")\n",
        "                wav, sampling_rate = torchaudio.load(audio_file)\n",
        "                speaker_embedding = model.make_speaker_embedding(wav, sampling_rate)\n",
        "                print(\"✅ 스피커 임베딩 생성 완료\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 음성 클로닝 실패: {e}\")\n",
        "                print(\"기본 스피커로 진행합니다.\")\n",
        "\n",
        "        # 감정 벡터 구성 (공식 문서 기본값)\n",
        "        emotion_vector = [happiness, sadness, disgust, fear, surprise, anger, other, neutral]\n",
        "        print(f\"🎭 감정 벡터: {emotion_vector}\")\n",
        "\n",
        "        # 무조건적 설정 구성 (공식 문서 기본값: {\"vqscore_8\", \"dnsmos_ovrl\"})\n",
        "        unconditional_keys = {\"vqscore_8\", \"dnsmos_ovrl\"}  # 공식 기본값\n",
        "        \n",
        "        # 사용자 설정 무조건적 설정\n",
        "        if emotion_unconditional:\n",
        "            unconditional_keys.add(\"emotion\")\n",
        "        if speaker_unconditional:\n",
        "            unconditional_keys.add(\"speaker\")\n",
        "        if fmax_unconditional:\n",
        "            unconditional_keys.add(\"fmax\")\n",
        "        if pitch_unconditional:\n",
        "            unconditional_keys.add(\"pitch_std\")\n",
        "        if rate_unconditional:\n",
        "            unconditional_keys.add(\"speaking_rate\")\n",
        "        \n",
        "        print(f\"🔓 무조건적 설정: {unconditional_keys}\")\n",
        "\n",
        "        # 텍스트 전처리\n",
        "        print(f\"📝 원본 텍스트: '{text}'\")\n",
        "        processed_text = text.strip()\n",
        "        print(f\"📝 처리된 텍스트: '{processed_text}'\")\n",
        "\n",
        "        # 조건 설정 (공식 문서 기준)\n",
        "        print(\"🔧 조건 설정 중...\")\n",
        "        cond_dict = make_cond_dict(\n",
        "            text=processed_text,\n",
        "            speaker=speaker_embedding,\n",
        "            language=language,\n",
        "            emotion=emotion_vector,\n",
        "            speaking_rate=speaking_rate,\n",
        "            pitch_std=pitch_std,\n",
        "            fmax=fmax,\n",
        "            unconditional_keys=unconditional_keys\n",
        "        )\n",
        "        print(\"✅ 조건 설정 완료\")\n",
        "        print(f\"🔍 espeak 텍스트: {cond_dict.get('espeak', 'N/A')}\")\n",
        "\n",
        "        # 조건 준비\n",
        "        print(\"🎯 조건 준비 중...\")\n",
        "        conditioning = model.prepare_conditioning(cond_dict)\n",
        "        print(\"✅ 조건 준비 완료\")\n",
        "\n",
        "        # 음성 생성 (공식 코드와 동일한 파라미터 사용)\n",
        "        print(\"🎵 음성 생성 중... (시간이 걸릴 수 있습니다)\")\n",
        "        codes = model.generate(\n",
        "            conditioning,\n",
        "            cfg_scale=2.0,  # 공식 기본값\n",
        "            batch_size=1,\n",
        "            sampling_params=dict(\n",
        "                top_p=0.0,\n",
        "                top_k=0,\n",
        "                min_p=0.0,\n",
        "                linear=0.5,\n",
        "                conf=0.40,\n",
        "                quad=0.00\n",
        "            )\n",
        "        )\n",
        "        print(\"✅ 음성 생성 완료\")\n",
        "\n",
        "        # 디코딩\n",
        "        print(\"🔊 디코딩 중...\")\n",
        "        wavs = model.autoencoder.decode(codes).cpu()\n",
        "        print(\"✅ 디코딩 완료\")\n",
        "\n",
        "        # 결과 저장\n",
        "        output_file = \"generated_speech.wav\"\n",
        "        torchaudio.save(output_file, wavs[0], model.autoencoder.sampling_rate)\n",
        "        print(f\"✅ 음성 파일 저장 완료: {output_file}\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return output_file, f\"시드: {used_seed}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ 오류 발생: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        import traceback\n",
        "        print(\"상세 오류:\")\n",
        "        traceback.print_exc()\n",
        "        return error_msg, \"오류 발생\"\n",
        "\n",
        "# Gradio 인터페이스 생성 (공식 데모와 동일한 구조)\n",
        "with gr.Blocks(title=\"Zonos TTS - 구글 코랩\") as demo:\n",
        "    gr.Markdown(\"# 🎵 Zonos TTS - 구글 코랩\")\n",
        "    gr.Markdown(\"텍스트를 음성으로 변환하는 고급 TTS 시스템입니다.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"텍스트 입력\",\n",
        "                placeholder=\"여기에 변환할 텍스트를 입력하세요...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            language = gr.Dropdown(\n",
        "                choices=[\"en-us\", \"ko\", \"ja\", \"zh\", \"fr\", \"de\"],\n",
        "                value=\"en-us\",\n",
        "                label=\"언어 선택\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"🎭 감정 설정\", open=False):\n",
        "                gr.Markdown(\"감정 벡터 (0.0-1.0): Happiness, Sadness, Disgust, Fear, Surprise, Anger, Other, Neutral\")\n",
        "                \n",
        "                happiness = gr.Slider(0.0, 1.0, value=0.3077, step=0.0001, label=\"Happiness (행복)\")\n",
        "                sadness = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Sadness (슬픔)\")\n",
        "                disgust = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Disgust (혐오)\")\n",
        "                fear = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Fear (두려움)\")\n",
        "                surprise = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Surprise (놀람)\")\n",
        "                anger = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Anger (분노)\")\n",
        "                other = gr.Slider(0.0, 1.0, value=0.2564, step=0.0001, label=\"Other (기타)\")\n",
        "                neutral = gr.Slider(0.0, 1.0, value=0.3077, step=0.0001, label=\"Neutral (중립)\")\n",
        "            \n",
        "            speaking_rate = gr.Slider(\n",
        "                minimum=0.0,\n",
        "                maximum=40.0,\n",
        "                value=15.0,\n",
        "                step=1.0,\n",
        "                label=\"Speaking Rate (0-40 phonemes per minute, 30=very fast, 10=slow)\"\n",
        "            )\n",
        "\n",
        "            pitch_std = gr.Slider(\n",
        "                minimum=0.0,\n",
        "                maximum=400.0,\n",
        "                value=20.0,\n",
        "                step=5.0,\n",
        "                label=\"Pitch Std (0-400, 20-45=normal, 60-150=expressive, higher=crazier)\"\n",
        "            )\n",
        "\n",
        "            fmax = gr.Slider(\n",
        "                minimum=0, maximum=24000, value=22050, step=50,\n",
        "                label=\"Fmax (Hz) - 22050=44.1kHz, 24000=48kHz, 22050 for voice cloning\"\n",
        "            )\n",
        "\n",
        "            seed = gr.Number(\n",
        "                value=None,\n",
        "                label=\"Seed (for reproducible results, leave empty for random)\",\n",
        "                precision=0\n",
        "            )\n",
        "\n",
        "            audio_file = gr.Audio(\n",
        "                label=\"Voice Cloning Audio (10-30 seconds recommended, optional)\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"⚙️ Advanced Settings\", open=False):\n",
        "                gr.Markdown(\"### Unconditional Keys\")\n",
        "                gr.Markdown(\"Check to make the parameter unconditional (auto-filled by model)\")\n",
        "                speaker_unconditional = gr.Checkbox(label=\"speaker\", value=False)\n",
        "                emotion_unconditional = gr.Checkbox(label=\"emotion\", value=False)\n",
        "                fmax_unconditional = gr.Checkbox(label=\"fmax\", value=False)\n",
        "                pitch_unconditional = gr.Checkbox(label=\"pitch_std\", value=False)\n",
        "                rate_unconditional = gr.Checkbox(label=\"speaking_rate\", value=False)\n",
        "\n",
        "            generate_btn = gr.Button(\"🎵 Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(label=\"Generated Speech\", type=\"filepath\")\n",
        "            current_seed = gr.Textbox(\n",
        "                label=\"Current Seed\",\n",
        "                value=\"Not generated yet\",\n",
        "                interactive=False,\n",
        "                info=\"Copy this seed to reproduce the same result later\"\n",
        "            )\n",
        "\n",
        "            # GPU 정보 표시\n",
        "            gpu_info = \"\"\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_name = torch.cuda.get_device_name(0)\n",
        "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "                gpu_info = f\"🖥️ **GPU**: {gpu_name} ({gpu_memory:.1f} GB)\"\n",
        "            else:\n",
        "                gpu_info = \"❌ **GPU**: Not available (CPU mode)\"\n",
        "            \n",
        "            gr.Markdown(f\"\"\"\n",
        "            ### 🖥️ System Info:\n",
        "            {gpu_info}\n",
        "            \n",
        "            ### 🌐 Supported Languages:\n",
        "            - **English (en-us)**: Hello, how are you?\n",
        "            - **한국어 (ko)**: 안녕하세요, 반갑습니다!\n",
        "            - **日本語 (ja)**: こんにちは、元気ですか？\n",
        "            - **中文 (zh)**: 你好，最近怎么样？\n",
        "            - **Français (fr)**: Bonjour, comment allez-vous ?\n",
        "            - **Deutsch (de)**: Hallo, wie geht es Ihnen?\n",
        "\n",
        "            ### 🎯 Key Features:\n",
        "            - **Seed Control**: Use same seed for reproducible results\n",
        "            - **Voice Cloning**: Upload 10-30s audio for zero-shot voice cloning\n",
        "            - **Emotion Control**: Fine-tune 8 emotion dimensions\n",
        "            - **Speech Parameters**: Adjust speaking rate, pitch variation, frequency range\n",
        "\n",
        "            ### 📖 Usage:\n",
        "            1. Enter text to convert\n",
        "            2. Select language and adjust emotions\n",
        "            3. Tune speaking rate and pitch\n",
        "            4. Set seed for reproducibility (optional)\n",
        "            5. Upload audio for voice cloning (optional)\n",
        "            6. Click \"Generate Speech\"\n",
        "            7. Play or download the generated audio\n",
        "            \"\"\")\n",
        "\n",
        "    # 이벤트 연결\n",
        "    generate_btn.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[text_input, language, happiness, sadness, disgust, fear, surprise, anger, other, neutral, emotion_unconditional, speaking_rate, pitch_std, fmax, speaker_unconditional, fmax_unconditional, pitch_unconditional, rate_unconditional, seed, audio_file],\n",
        "        outputs=[audio_output, current_seed]\n",
        "    )\n",
        "\n",
        "# 인터페이스 실행 (퍼블릭 링크 생성)\n",
        "print(\"=== Gradio 웹 인터페이스 실행 ===\")\n",
        "print(\"퍼블릭 링크가 생성되면 브라우저에서 접속할 수 있습니다.\")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
