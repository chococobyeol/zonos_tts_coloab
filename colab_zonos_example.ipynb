{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸµ Zonos TTS - êµ¬ê¸€ ì½”ë©\n",
        "\n",
        "Zonos Text-to-Speech ëª¨ë¸ì„ êµ¬ê¸€ ì½”ë©ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n",
        "\n",
        "## ê³µì‹ ë¬¸ì„œ ê¸°ì¤€ ì •í™•í•œ êµ¬í˜„\n",
        "- **make_cond_dict** íŒŒë¼ë¯¸í„°: ê³µì‹ ë¬¸ì„œì™€ 100% ì¼ì¹˜\n",
        "- **ê°ì • ë²¡í„°**: [0.3077, 0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.2564, 0.3077]\n",
        "- **speaking_rate**: 0-40 (30=very fast, 10=slow)\n",
        "- **pitch_std**: 0-400 (20-45=normal, 60-150=expressive)\n",
        "- **fmax**: 22050 (44.1kHz) ë˜ëŠ” 24000 (48kHz)\n",
        "- **unconditional_keys**: ê¸°ë³¸ê°’ {\"vqscore_8\", \"dnsmos_ovrl\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (eSpeak-ng)\n",
        "!apt-get update\n",
        "!apt-get install -y espeak-ng\n",
        "\n",
        "# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers gradio\n",
        "\n",
        "# 3. Zonos ì €ì¥ì†Œ í´ë¡ \n",
        "!git clone https://github.com/Zyphra/Zonos.git\n",
        "%cd Zonos\n",
        "\n",
        "# 4. Zonos ì„¤ì¹˜\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from zonos.model import Zonos\n",
        "from zonos.conditioning import make_cond_dict\n",
        "from zonos.utils import DEFAULT_DEVICE as device\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ (Transformer ë²„ì „ ì‚¬ìš©)\n",
        "print(\"ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
        "print(\"ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
        "\n",
        "# ê¸°ë³¸ ìƒ˜í”Œ ì‹¤í–‰ (ê³µì‹ ë¬¸ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
        "text = \"Hello, this is a test of Zonos text-to-speech in Google Colab!\"\n",
        "cond_dict = make_cond_dict(\n",
        "    text=text, \n",
        "    speaker=None, \n",
        "    language=\"en-us\",\n",
        "    # ê³µì‹ ë¬¸ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©\n",
        "    emotion=[0.3077, 0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.2564, 0.3077],\n",
        "    speaking_rate=15.0,\n",
        "    pitch_std=20.0,\n",
        "    fmax=22050.0\n",
        ")\n",
        "conditioning = model.prepare_conditioning(cond_dict)\n",
        "print(\"ìŒì„± ìƒì„± ì¤‘...\")\n",
        "codes = model.generate(conditioning)\n",
        "wavs = model.autoencoder.decode(codes).cpu()\n",
        "output_file = \"sample.wav\"\n",
        "torchaudio.save(output_file, wavs[0], model.autoencoder.sampling_rate)\n",
        "print(f\"âœ… ìŒì„± íŒŒì¼ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# êµ¬ê¸€ ì½”ë©ìš© Gradio ì¸í„°í˜ì´ìŠ¤ (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€ ì •í™•í•œ êµ¬í˜„)\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from zonos.model import Zonos\n",
        "from zonos.conditioning import make_cond_dict\n",
        "from zonos.utils import DEFAULT_DEVICE as device\n",
        "import gc\n",
        "\n",
        "# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜ í™•ì¸ ë° ë¡œë“œ\n",
        "print(\"ğŸ” ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
        "if 'model' not in globals():\n",
        "    print(\"âš ï¸ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Gradioì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
        "    try:\n",
        "        model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
        "        print(\"âœ… Gradioì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        model = None\n",
        "else:\n",
        "    print(\"âœ… ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# TTS í•¨ìˆ˜ ì •ì˜ (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€ ì •í™•í•œ íŒŒë¼ë¯¸í„°)\n",
        "def generate_speech(text, language=\"en-us\", happiness=0.3077, sadness=0.0256, disgust=0.0256, fear=0.0256, surprise=0.0256, anger=0.0256, other=0.2564, neutral=0.3077, emotion_unconditional=False, speaking_rate=15.0, pitch_std=20.0, fmax=22050.0, speaker_unconditional=False, fmax_unconditional=False, pitch_unconditional=False, rate_unconditional=False, seed=None, audio_file=None):\n",
        "    try:\n",
        "        print(f\"ğŸ” ë””ë²„ê¹…: í…ìŠ¤íŠ¸='{text}', ì–¸ì–´='{language}', ì‹œë“œ='{seed}', ì˜¤ë””ì˜¤íŒŒì¼='{audio_file}'\")\n",
        "\n",
        "        # ëª¨ë¸ í™•ì¸\n",
        "        if model is None:\n",
        "            return \"âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\", \"ì˜¤ë¥˜ ë°œìƒ\"\n",
        "\n",
        "        print(\"âœ… ëª¨ë¸ í™•ì¸ ì™„ë£Œ\")\n",
        "\n",
        "        # ì‹œë“œ ì„¤ì •\n",
        "        if seed is not None:\n",
        "            torch.manual_seed(seed)\n",
        "            used_seed = seed\n",
        "            print(f\"ğŸ² ì‹œë“œ ì„¤ì •: {seed}\")\n",
        "        else:\n",
        "            # ëœë¤ ì‹œë“œ ìƒì„±\n",
        "            used_seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
        "            torch.manual_seed(used_seed)\n",
        "            print(f\"ğŸ² ëœë¤ ì‹œë“œ ìƒì„±: {used_seed}\")\n",
        "\n",
        "        # ìŒì„± í´ë¡œë‹ ì²˜ë¦¬\n",
        "        speaker_embedding = None\n",
        "        if audio_file is not None:\n",
        "            try:\n",
        "                print(\"ğŸ¤ ìŒì„± í´ë¡œë‹ ì²˜ë¦¬ ì¤‘...\")\n",
        "                wav, sampling_rate = torchaudio.load(audio_file)\n",
        "                speaker_embedding = model.make_speaker_embedding(wav, sampling_rate)\n",
        "                print(\"âœ… ìŠ¤í”¼ì»¤ ì„ë² ë”© ìƒì„± ì™„ë£Œ\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ ìŒì„± í´ë¡œë‹ ì‹¤íŒ¨: {e}\")\n",
        "                print(\"ê¸°ë³¸ ìŠ¤í”¼ì»¤ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "        # ê°ì • ë²¡í„° êµ¬ì„± (ê³µì‹ ë¬¸ì„œ ê¸°ë³¸ê°’)\n",
        "        emotion_vector = [happiness, sadness, disgust, fear, surprise, anger, other, neutral]\n",
        "        print(f\"ğŸ­ ê°ì • ë²¡í„°: {emotion_vector}\")\n",
        "\n",
        "        # ë¬´ì¡°ê±´ì  ì„¤ì • êµ¬ì„± (ê³µì‹ ë¬¸ì„œ ê¸°ë³¸ê°’: {\"vqscore_8\", \"dnsmos_ovrl\"})\n",
        "        unconditional_keys = {\"vqscore_8\", \"dnsmos_ovrl\"}  # ê³µì‹ ê¸°ë³¸ê°’\n",
        "        \n",
        "        # ì‚¬ìš©ì ì„¤ì • ë¬´ì¡°ê±´ì  ì„¤ì •\n",
        "        if emotion_unconditional:\n",
        "            unconditional_keys.add(\"emotion\")\n",
        "        if speaker_unconditional:\n",
        "            unconditional_keys.add(\"speaker\")\n",
        "        if fmax_unconditional:\n",
        "            unconditional_keys.add(\"fmax\")\n",
        "        if pitch_unconditional:\n",
        "            unconditional_keys.add(\"pitch_std\")\n",
        "        if rate_unconditional:\n",
        "            unconditional_keys.add(\"speaking_rate\")\n",
        "        \n",
        "        print(f\"ğŸ”“ ë¬´ì¡°ê±´ì  ì„¤ì •: {unconditional_keys}\")\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "        print(f\"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸: '{text}'\")\n",
        "        processed_text = text.strip()\n",
        "        print(f\"ğŸ“ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸: '{processed_text}'\")\n",
        "\n",
        "        # ì¡°ê±´ ì„¤ì • (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)\n",
        "        print(\"ğŸ”§ ì¡°ê±´ ì„¤ì • ì¤‘...\")\n",
        "        cond_dict = make_cond_dict(\n",
        "            text=processed_text,\n",
        "            speaker=speaker_embedding,\n",
        "            language=language,\n",
        "            emotion=emotion_vector,\n",
        "            speaking_rate=speaking_rate,\n",
        "            pitch_std=pitch_std,\n",
        "            fmax=fmax,\n",
        "            unconditional_keys=unconditional_keys\n",
        "        )\n",
        "        print(\"âœ… ì¡°ê±´ ì„¤ì • ì™„ë£Œ\")\n",
        "        print(f\"ğŸ” espeak í…ìŠ¤íŠ¸: {cond_dict.get('espeak', 'N/A')}\")\n",
        "\n",
        "        # ì¡°ê±´ ì¤€ë¹„\n",
        "        print(\"ğŸ¯ ì¡°ê±´ ì¤€ë¹„ ì¤‘...\")\n",
        "        conditioning = model.prepare_conditioning(cond_dict)\n",
        "        print(\"âœ… ì¡°ê±´ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "\n",
        "        # ìŒì„± ìƒì„± (ê³µì‹ ì½”ë“œì™€ ë™ì¼í•œ íŒŒë¼ë¯¸í„° ì‚¬ìš©)\n",
        "        print(\"ğŸµ ìŒì„± ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
        "        codes = model.generate(\n",
        "            conditioning,\n",
        "            cfg_scale=2.0,  # ê³µì‹ ê¸°ë³¸ê°’\n",
        "            batch_size=1,\n",
        "            sampling_params=dict(\n",
        "                top_p=0.0,\n",
        "                top_k=0,\n",
        "                min_p=0.0,\n",
        "                linear=0.5,\n",
        "                conf=0.40,\n",
        "                quad=0.00\n",
        "            )\n",
        "        )\n",
        "        print(\"âœ… ìŒì„± ìƒì„± ì™„ë£Œ\")\n",
        "\n",
        "        # ë””ì½”ë”©\n",
        "        print(\"ğŸ”Š ë””ì½”ë”© ì¤‘...\")\n",
        "        wavs = model.autoencoder.decode(codes).cpu()\n",
        "        print(\"âœ… ë””ì½”ë”© ì™„ë£Œ\")\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥\n",
        "        output_file = \"generated_speech.wav\"\n",
        "        torchaudio.save(output_file, wavs[0], model.autoencoder.sampling_rate)\n",
        "        print(f\"âœ… ìŒì„± íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return output_file, f\"ì‹œë“œ: {used_seed}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        import traceback\n",
        "        print(\"ìƒì„¸ ì˜¤ë¥˜:\")\n",
        "        traceback.print_exc()\n",
        "        return error_msg, \"ì˜¤ë¥˜ ë°œìƒ\"\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ê³µì‹ ë°ëª¨ì™€ ë™ì¼í•œ êµ¬ì¡°)\n",
        "with gr.Blocks(title=\"Zonos TTS - êµ¬ê¸€ ì½”ë©\") as demo:\n",
        "    gr.Markdown(\"# ğŸµ Zonos TTS - êµ¬ê¸€ ì½”ë©\")\n",
        "    gr.Markdown(\"í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³ ê¸‰ TTS ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"í…ìŠ¤íŠ¸ ì…ë ¥\",\n",
        "                placeholder=\"ì—¬ê¸°ì— ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            language = gr.Dropdown(\n",
        "                choices=[\"en-us\", \"ko\", \"ja\", \"zh\", \"fr\", \"de\"],\n",
        "                value=\"en-us\",\n",
        "                label=\"ì–¸ì–´ ì„ íƒ\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"ğŸ­ ê°ì • ì„¤ì •\", open=False):\n",
        "                gr.Markdown(\"ê°ì • ë²¡í„° (0.0-1.0): Happiness, Sadness, Disgust, Fear, Surprise, Anger, Other, Neutral\")\n",
        "                \n",
        "                happiness = gr.Slider(0.0, 1.0, value=0.3077, step=0.0001, label=\"Happiness (í–‰ë³µ)\")\n",
        "                sadness = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Sadness (ìŠ¬í””)\")\n",
        "                disgust = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Disgust (í˜ì˜¤)\")\n",
        "                fear = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Fear (ë‘ë ¤ì›€)\")\n",
        "                surprise = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Surprise (ë†€ëŒ)\")\n",
        "                anger = gr.Slider(0.0, 1.0, value=0.0256, step=0.0001, label=\"Anger (ë¶„ë…¸)\")\n",
        "                other = gr.Slider(0.0, 1.0, value=0.2564, step=0.0001, label=\"Other (ê¸°íƒ€)\")\n",
        "                neutral = gr.Slider(0.0, 1.0, value=0.3077, step=0.0001, label=\"Neutral (ì¤‘ë¦½)\")\n",
        "            \n",
        "            speaking_rate = gr.Slider(\n",
        "                minimum=0.0,\n",
        "                maximum=40.0,\n",
        "                value=15.0,\n",
        "                step=1.0,\n",
        "                label=\"Speaking Rate (0-40 phonemes per minute, 30=very fast, 10=slow)\"\n",
        "            )\n",
        "\n",
        "            pitch_std = gr.Slider(\n",
        "                minimum=0.0,\n",
        "                maximum=400.0,\n",
        "                value=20.0,\n",
        "                step=5.0,\n",
        "                label=\"Pitch Std (0-400, 20-45=normal, 60-150=expressive, higher=crazier)\"\n",
        "            )\n",
        "\n",
        "            fmax = gr.Slider(\n",
        "                minimum=0, maximum=24000, value=22050, step=50,\n",
        "                label=\"Fmax (Hz) - 22050=44.1kHz, 24000=48kHz, 22050 for voice cloning\"\n",
        "            )\n",
        "\n",
        "            seed = gr.Number(\n",
        "                value=None,\n",
        "                label=\"Seed (for reproducible results, leave empty for random)\",\n",
        "                precision=0\n",
        "            )\n",
        "\n",
        "            audio_file = gr.Audio(\n",
        "                label=\"Voice Cloning Audio (10-30 seconds recommended, optional)\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"âš™ï¸ Advanced Settings\", open=False):\n",
        "                gr.Markdown(\"### Unconditional Keys\")\n",
        "                gr.Markdown(\"Check to make the parameter unconditional (auto-filled by model)\")\n",
        "                speaker_unconditional = gr.Checkbox(label=\"speaker\", value=False)\n",
        "                emotion_unconditional = gr.Checkbox(label=\"emotion\", value=False)\n",
        "                fmax_unconditional = gr.Checkbox(label=\"fmax\", value=False)\n",
        "                pitch_unconditional = gr.Checkbox(label=\"pitch_std\", value=False)\n",
        "                rate_unconditional = gr.Checkbox(label=\"speaking_rate\", value=False)\n",
        "\n",
        "            generate_btn = gr.Button(\"ğŸµ Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(label=\"Generated Speech\", type=\"filepath\")\n",
        "            current_seed = gr.Textbox(\n",
        "                label=\"Current Seed\",\n",
        "                value=\"Not generated yet\",\n",
        "                interactive=False,\n",
        "                info=\"Copy this seed to reproduce the same result later\"\n",
        "            )\n",
        "\n",
        "            # GPU ì •ë³´ í‘œì‹œ\n",
        "            gpu_info = \"\"\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_name = torch.cuda.get_device_name(0)\n",
        "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "                gpu_info = f\"ğŸ–¥ï¸ **GPU**: {gpu_name} ({gpu_memory:.1f} GB)\"\n",
        "            else:\n",
        "                gpu_info = \"âŒ **GPU**: Not available (CPU mode)\"\n",
        "            \n",
        "            gr.Markdown(f\"\"\"\n",
        "            ### ğŸ–¥ï¸ System Info:\n",
        "            {gpu_info}\n",
        "            \n",
        "            ### ğŸŒ Supported Languages:\n",
        "            - **English (en-us)**: Hello, how are you?\n",
        "            - **í•œêµ­ì–´ (ko)**: ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤!\n",
        "            - **æ—¥æœ¬èª (ja)**: ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ\n",
        "            - **ä¸­æ–‡ (zh)**: ä½ å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ\n",
        "            - **FranÃ§ais (fr)**: Bonjour, comment allez-vous ?\n",
        "            - **Deutsch (de)**: Hallo, wie geht es Ihnen?\n",
        "\n",
        "            ### ğŸ¯ Key Features:\n",
        "            - **Seed Control**: Use same seed for reproducible results\n",
        "            - **Voice Cloning**: Upload 10-30s audio for zero-shot voice cloning\n",
        "            - **Emotion Control**: Fine-tune 8 emotion dimensions\n",
        "            - **Speech Parameters**: Adjust speaking rate, pitch variation, frequency range\n",
        "\n",
        "            ### ğŸ“– Usage:\n",
        "            1. Enter text to convert\n",
        "            2. Select language and adjust emotions\n",
        "            3. Tune speaking rate and pitch\n",
        "            4. Set seed for reproducibility (optional)\n",
        "            5. Upload audio for voice cloning (optional)\n",
        "            6. Click \"Generate Speech\"\n",
        "            7. Play or download the generated audio\n",
        "            \"\"\")\n",
        "\n",
        "    # ì´ë²¤íŠ¸ ì—°ê²°\n",
        "    generate_btn.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[text_input, language, happiness, sadness, disgust, fear, surprise, anger, other, neutral, emotion_unconditional, speaking_rate, pitch_std, fmax, speaker_unconditional, fmax_unconditional, pitch_unconditional, rate_unconditional, seed, audio_file],\n",
        "        outputs=[audio_output, current_seed]\n",
        "    )\n",
        "\n",
        "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ (í¼ë¸”ë¦­ ë§í¬ ìƒì„±)\n",
        "print(\"=== Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ ===\")\n",
        "print(\"í¼ë¸”ë¦­ ë§í¬ê°€ ìƒì„±ë˜ë©´ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
